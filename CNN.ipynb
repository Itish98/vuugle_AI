{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b582a2e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-18 15:53:17.617114: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-18 15:53:21.688861: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-18 15:53:28.775144: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-18 15:53:28.775353: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-18 15:53:28.775375: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.set_random_seed(2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bca45dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-18 15:53:44.458876: E tensorflow/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-11-18 15:53:44.458968: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (itish-HP-Pavilion-Gaming-Laptop-15-dk1xxx): /proc/driver/nvidia/version does not exist\n",
      "2022-11-18 15:53:44.481362: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-18 15:53:45.206394: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 22809600 exceeds 10% of free system memory.\n",
      "2022-11-18 15:53:45.214372: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 22809600 exceeds 10% of free system memory.\n",
      "2022-11-18 15:53:45.218405: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 22809600 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(16,(3,3),activation = \"relu\" , input_shape = (180,180,3)) ,\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(32,(3,3),activation = \"relu\") ,  \n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64,(3,3),activation = \"relu\") ,  \n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(128,(3,3),activation = \"relu\"),  \n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(), \n",
    "    tf.keras.layers.Dense(550,activation=\"relu\"),      #Adding the Hidden layer\n",
    "    tf.keras.layers.Dropout(0.1,seed = 2019),\n",
    "    tf.keras.layers.Dense(400,activation =\"relu\"),\n",
    "    tf.keras.layers.Dropout(0.3,seed = 2019),\n",
    "    tf.keras.layers.Dense(300,activation=\"relu\"),\n",
    "    tf.keras.layers.Dropout(0.4,seed = 2019),\n",
    "    tf.keras.layers.Dense(200,activation =\"relu\"),\n",
    "    tf.keras.layers.Dropout(0.2,seed = 2019),\n",
    "    tf.keras.layers.Dense(7,activation = \"softmax\")   #Adding the Output Layer\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8c68e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 178, 178, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 89, 89, 16)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 87, 87, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 43, 43, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 41, 41, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 20, 20, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 18, 18, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 9, 9, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 10368)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 550)               5702950   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 550)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 400)               220400    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 400)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 300)               120300    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 300)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 200)               60200     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 200)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 7)                 1407      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,202,697\n",
      "Trainable params: 6,202,697\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab8c5ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop,SGD,Adam\n",
    "adam=Adam(lr=0.001)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a584e19e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 168 images belonging to 7 classes.\n",
      "Found 168 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "bs=30         #Setting batch size\n",
    "train_dir = \"/home/itish/Downloads/voogle/train\"   #Setting training directory\n",
    "validation_dir = \"/home/itish/Downloads/voogle/train\"   #Setting testing directory\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator \n",
    "# All images will be rescaled by 1./255.\n",
    "train_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
    "test_datagen  = ImageDataGenerator( rescale = 1.0/255. )\n",
    "# Flow training images in batches of 20 using train_datagen generator\n",
    "#Flow_from_directory function lets the classifier directly identify the labels from the name of the directories the image lies in\n",
    "train_generator=train_datagen.flow_from_directory(train_dir,batch_size=bs,class_mode='categorical',target_size=(180,180))\n",
    "# Flow validation images in batches of 20 using test_datagen generator\n",
    "validation_generator =  test_datagen.flow_from_directory(validation_dir,\n",
    "                                                         batch_size=bs,\n",
    "                                                         class_mode  = 'categorical',\n",
    "                                                         target_size=(180,180))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6213d45f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-18 15:53:47.341960: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 22809600 exceeds 10% of free system memory.\n",
      "2022-11-18 15:53:47.352146: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 22809600 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 - 5s - loss: 1.9939 - acc: 0.1884 - val_loss: 1.9013 - val_acc: 0.3000 - 5s/epoch - 914ms/step\n",
      "Epoch 2/20\n",
      "5/5 - 3s - loss: 1.9146 - acc: 0.2101 - val_loss: 1.8121 - val_acc: 0.4333 - 3s/epoch - 524ms/step\n",
      "Epoch 3/20\n",
      "5/5 - 3s - loss: 1.7500 - acc: 0.4933 - val_loss: 1.1943 - val_acc: 1.0000 - 3s/epoch - 512ms/step\n",
      "Epoch 4/20\n",
      "5/5 - 2s - loss: 0.9752 - acc: 0.7391 - val_loss: 0.1209 - val_acc: 1.0000 - 2s/epoch - 488ms/step\n",
      "Epoch 5/20\n",
      "5/5 - 2s - loss: 0.2388 - acc: 0.9420 - val_loss: 0.0012 - val_acc: 1.0000 - 2s/epoch - 496ms/step\n",
      "Epoch 6/20\n",
      "5/5 - 2s - loss: 0.0456 - acc: 0.9855 - val_loss: 1.7365e-06 - val_acc: 1.0000 - 2s/epoch - 498ms/step\n",
      "Epoch 7/20\n",
      "5/5 - 3s - loss: 0.0073 - acc: 1.0000 - val_loss: 2.3762e-06 - val_acc: 1.0000 - 3s/epoch - 505ms/step\n",
      "Epoch 8/20\n",
      "5/5 - 3s - loss: 0.0074 - acc: 1.0000 - val_loss: 9.9341e-08 - val_acc: 1.0000 - 3s/epoch - 507ms/step\n",
      "Epoch 9/20\n",
      "5/5 - 2s - loss: 0.0375 - acc: 0.9928 - val_loss: 2.1775e-06 - val_acc: 1.0000 - 2s/epoch - 481ms/step\n",
      "Epoch 10/20\n",
      "5/5 - 2s - loss: 0.2230 - acc: 0.9638 - val_loss: 0.6179 - val_acc: 0.8333 - 2s/epoch - 478ms/step\n",
      "Epoch 11/20\n",
      "5/5 - 2s - loss: 0.1781 - acc: 0.9710 - val_loss: 4.2518e-07 - val_acc: 1.0000 - 2s/epoch - 468ms/step\n",
      "Epoch 12/20\n",
      "5/5 - 2s - loss: 0.0378 - acc: 0.9855 - val_loss: 1.1841e-04 - val_acc: 1.0000 - 2s/epoch - 475ms/step\n",
      "Epoch 13/20\n",
      "5/5 - 2s - loss: 0.0300 - acc: 0.9928 - val_loss: 7.1552e-05 - val_acc: 1.0000 - 2s/epoch - 467ms/step\n",
      "Epoch 14/20\n",
      "5/5 - 2s - loss: 0.0268 - acc: 0.9855 - val_loss: 2.6729e-04 - val_acc: 1.0000 - 2s/epoch - 465ms/step\n",
      "Epoch 15/20\n",
      "5/5 - 2s - loss: 0.0128 - acc: 0.9928 - val_loss: 3.3935e-05 - val_acc: 1.0000 - 2s/epoch - 455ms/step\n",
      "Epoch 16/20\n",
      "5/5 - 2s - loss: 0.0120 - acc: 0.9928 - val_loss: 1.4504e-06 - val_acc: 1.0000 - 2s/epoch - 469ms/step\n",
      "Epoch 17/20\n",
      "5/5 - 2s - loss: 0.0182 - acc: 0.9928 - val_loss: 0.0028 - val_acc: 1.0000 - 2s/epoch - 472ms/step\n",
      "Epoch 18/20\n",
      "5/5 - 2s - loss: 9.6759e-04 - acc: 1.0000 - val_loss: 1.0223e-05 - val_acc: 1.0000 - 2s/epoch - 491ms/step\n",
      "Epoch 19/20\n",
      "5/5 - 2s - loss: 0.0028 - acc: 1.0000 - val_loss: 7.4619e-06 - val_acc: 1.0000 - 2s/epoch - 473ms/step\n",
      "Epoch 20/20\n",
      "5/5 - 2s - loss: 0.0035 - acc: 1.0000 - val_loss: 2.9921e-06 - val_acc: 1.0000 - 2s/epoch - 472ms/step\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator,\n",
    "                    validation_data=validation_generator,\n",
    "                    steps_per_epoch=150 // bs,\n",
    "                    epochs=20,\n",
    "                    validation_steps=50 // bs,\n",
    "                    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6780a4e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model.save(\"skyfall.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8158035e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to predict new images \n",
    "def predict_image(imagepath, classifier):\n",
    "    predict = load_img(imagepath, target_size = (180, 180))   \n",
    "    predict_modified = img_to_array(predict)\n",
    "    predict_modified = predict_modified / 255\n",
    "    predict_modified = np.expand_dims(predict_modified, axis = 0)\n",
    "    result = classifier.predict(predict_modified)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc0ace18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 390ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.0189370e-08, 8.6359693e-09, 7.0101713e-08, 1.7272967e-08,\n",
       "        2.6857589e-09, 3.2923498e-07, 9.9999952e-01]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import load_img\n",
    "from tensorflow.keras.utils import img_to_array\n",
    "predict_image('/home/itish/Downloads/voogle/test.jpg',model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706cdf2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
